{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HH "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %pip install uproot awkward numpy particle vector networkx matplotlib\n",
    "# print()\n",
    "# print(\"###############\")\n",
    "# print(\"conda packages:\")\n",
    "# print(\"###############\")\n",
    "# print()\n",
    "# %conda list uproot\n",
    "# %conda list awkward\n",
    "# %conda list numpy\n",
    "# %conda list particle\n",
    "# %conda list vector\n",
    "# %conda list networkx\n",
    "# %conda list matplotlib\n",
    "# print()\n",
    "# print(\"#############\")\n",
    "# print(\"pip packages:\")\n",
    "# print(\"#############\")\n",
    "# print()\n",
    "# %pip show uproot awkward numpy particle vector networkx matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system and misc\n",
    "import os\n",
    "import sys\n",
    "from types import MappingProxyType as immutable_dict # immutable dictionary\n",
    "\n",
    "# numpy and scipy\n",
    "import numpy as np\n",
    "np.set_printoptions(linewidth=120)\n",
    "from scipy import stats\n",
    "\n",
    "# uproot and awkward\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import vector\n",
    "vector.register_awkward()\n",
    "\n",
    "# gen particle stuff\n",
    "from particle import Particle\n",
    "import networkx as nx\n",
    "\n",
    "# histogramminng and plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from plothist import make_hist, plot_model\n",
    "import boost_histogram as bh\n",
    "import mplhep as hep\n",
    "hep.style.use(\"CMS\")\n",
    "\n",
    "# from common.py\n",
    "from common import build_decay_graph, print_hierarchy, export_decay_hierarchy, draw_decay_graph, process_gen_objects, process_event_data\n",
    "from common import print_summary, print_matching_base, print_matching\n",
    "from common import filter_events\n",
    "from common import objects, base_objects, gen_objects, jet_objects, tau_objects, muon_objects\n",
    "from common import L1Jet_objects, L1DJet_objects, L1Tau_objects, L1TauP2_objects, HLT_objects, L1Mu_objects\n",
    "from common import delta_phi, geometric_matching_base, geometric_matching\n",
    "from common import object_matching_base, object_matching, hlt_matching_base, hlt_matching\n",
    "from common import L1T_passing, HLT_passing\n",
    "from common import clopper_pearson_interval, plot_sig_eff_vs_jet_rank, plot_perf_vs_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG MODE\n",
    "debug = False\n",
    "\n",
    "settings_ = immutable_dict({\n",
    "    # Misc\n",
    "    \"debug\":debug, \n",
    "    \"nevents\":10000 if not debug else 10,\n",
    "    \"skip\":0 if not debug else 0,\n",
    "    \"verbosity\":0 if not debug else 3,\n",
    "    # Total integrated luminosity\n",
    "    \"lumi\":300,\n",
    "    # Kinematic thresholds\n",
    "    \"gen_pt_min\":10.,\n",
    "    \"gen_eta_max\":2.5,\n",
    "    \"off_pt_min\":35.,\n",
    "    \"off_eta_max\":2.5,\n",
    "    \"off_btag_min\":0.55,\n",
    "    \"sct_pt_min\":10.,\n",
    "    \"sct_eta_max\":2.5,\n",
    "    # Use only di-tau trigger, ParkingHH trigger, or the OR of both\n",
    "    \"option\":[\"tautau\",\"bb\",\"bbtautau\"][2],\n",
    "    # Match L1 and HLT objects to GEN\n",
    "    \"use_matched\":False,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bbbb (Run 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################\n",
    "#\n",
    "def qcd_gen_pt_hat_range(sample):\n",
    "    lower = float(sample.split(\"-\")[1].split(\"To\")[0])\n",
    "    upper = float(sample.split(\"To\")[1].replace(\"Inf\", str(np.inf)))\n",
    "    return lower,upper\n",
    "\n",
    "#############################################################################################\n",
    "#\n",
    "def load_datasets(samples, labels=None, path=\"../data/\", cross_sections=None, lumi=300., nevents=None, skip=0, verbosity=0):\n",
    "\n",
    "    branches = [\n",
    "        \"GenPart_pt\", \"GenPart_eta\", \"GenPart_phi\", # GEN-level kinematics\n",
    "        \"nGenPart\",\"GenPart_pdgId\", \"GenPart_genPartIdxMother\", \"GenPart_statusFlags\", # GEN-level information\n",
    "        #\"L1_HTT280er\", # L1 seeds\n",
    "        #\"HLT_PFHT280_QuadPFJet30_PNet2BTagMean0p55\", # HLT paths\n",
    "        #\"nTrigObj\", \"TrigObj_pt\", \"TrigObj_eta\", \"TrigObj_phi\", \"TrigObj_id\", \"TrigObj_filterBits\", # Trigger objects\n",
    "        \"Jet_pt\", \"Jet_eta\", \"Jet_phi\", \"Jet_btagPNetB\", # Offline jets\n",
    "        \"nL1Jet\", \"L1Jet_pt\", \"L1Jet_eta\", \"L1Jet_phi\", # L1 jets \n",
    "        #\"nL1Tau\", \"L1Tau_pt\", \"L1Tau_eta\", \"L1Tau_phi\", # L1 taus\n",
    "    ]\n",
    "\n",
    "    total = 0\n",
    "    datasets = {}\n",
    "    for i,sample in enumerate(samples):\n",
    "        events = uproot.concatenate(f\"{path}{sample}/data_?.root:Events\",branches,library=\"ak\")\n",
    "        events = events[skip:nevents+skip] if nevents is not None else events[skip:]\n",
    "        nevents = len(events)\n",
    "        weight = lumi * cross_sections[i] / nevents\n",
    "        events[\"weight\"] = ak.full_like(events[\"nGenPart\"],weight,dtype=\"float32\")\n",
    "        print(f\"Sample: {sample:15s} MC events: {nevents:8.2e} Weighted: {ak.sum(events.weight):8.2e}\")\n",
    "\n",
    "        if \"QCD\" in sample:\n",
    "            #lower,upper = qcd_gen_pt_hat_range(sample)\n",
    "            #events[\"lower_pt_hat\"] = ak.full_like(events[\"nGenPart\"], lower, dtype=\"float32\")\n",
    "            #events[\"upper_pt_hat\"] = ak.full_like(events[\"nGenPart\"], upper, dtype=\"float32\")\n",
    "            gen = gen_objects(events)\n",
    "            mask = ((abs(gen.id) <= 6)|(gen.id == 21)) & gen.is_hard_process & gen.is_prompt # identify quarks and gluons from the hard process\n",
    "            gen = ak.mask(gen,mask)\n",
    "            gen_pt_hat = ak.max(gen.pt,axis=-1) #@@ Why max and not sum ?\n",
    "            gen_pt_hat = ak.fill_none(gen_pt_hat,0.)\n",
    "            events[\"gen_pt_hat\"] = gen_pt_hat\n",
    "        elif \"HHTo4B\" in sample:\n",
    "            gen = gen_objects(events)\n",
    "            mask = ((abs(gen.id) == 25)) & gen.is_hard_process & gen.is_prompt # identify quarks and gluons from the hard process\n",
    "            #is_first_copy = (gen.first_copy == 1) & (gen.is_hard_process == 1)\n",
    "            #mask = (gen.id == 5) & is_last_copy & ~is_first_copy & gen.is_prompt # identify b quarks from Higgs decay\n",
    "            ##is_last_copy = (gen.last_copy == 1) & (gen.from_hard_process == 1)\n",
    "            gen = ak.mask(gen,mask)\n",
    "            gen_pt_hat = ak.sum(gen.pt,axis=-1)\n",
    "            gen_pt_hat = ak.fill_none(gen_pt_hat,0.)\n",
    "            events[\"gen_pt_hat\"] = gen_pt_hat\n",
    "        else:\n",
    "            events[\"gen_pt_hat\"]   = ak.full_like(events[\"nGenPart\"], 0., dtype=\"float32\")\n",
    "\n",
    "        datasets[sample] = {\"label\":labels[sample], \"events\":events}\n",
    "\n",
    "    events = ak.concatenate([datasets[sample][\"events\"] for sample in samples])\n",
    "    print(f\"Totals: {' '*15} MC events: {len(events):8.2e} Weighted: {ak.sum(events.weight):8.2e}\")\n",
    "    print()\n",
    "\n",
    "    if verbosity>=3:\n",
    "        keys = events.fields\n",
    "        print()\n",
    "        print(\"[load_data_bbbb]\")\n",
    "        print(\"All branches:\")\n",
    "        for key in keys:\n",
    "            print(f\"  {key}\")\n",
    "        print()\n",
    "        print(\"L1 seeds:\")\n",
    "        for key in keys:\n",
    "            if key.startswith(\"L1_\") : print(f\"  {key}\")\n",
    "        print()\n",
    "        print(\"HLT paths:\")\n",
    "        for key in keys:\n",
    "            if key.startswith(\"HLT_\") : print(f\"  {key}\")\n",
    "\n",
    "    return events, datasets\n",
    "\n",
    "#############################################################################################\n",
    "#\n",
    "def load_datasets_signal(lumi=300., nevents=None, skip=0, verbosity=0):\n",
    "\n",
    "    # Open ROOT file with uproot\n",
    "    samples = [\n",
    "        \"HHTo4B\",\n",
    "#        \"HHTo2B2Tau\",\n",
    "    ]\n",
    "\n",
    "    cross_sections_pb = [\n",
    "        0.01575,\n",
    "#        0.01575,\n",
    "    ]\n",
    "    cross_sections_fb = [ xs * 1.e3 for xs in cross_sections_pb]\n",
    "\n",
    "    labels = [\n",
    "        \"HH${\\\\to}$bbbb\",\n",
    " #       \"HH${\\\\to}$bb$\\\\tau\\\\tau$\",\n",
    "    ]\n",
    "    labels = dict(zip(samples,labels))\n",
    "\n",
    "    return load_datasets(\n",
    "        samples,\n",
    "        labels=labels,\n",
    "        path=\"../data/Phase2/\",\n",
    "        cross_sections=cross_sections_fb,\n",
    "        lumi=lumi,\n",
    "        nevents=nevents, skip=skip, verbosity=verbosity)\n",
    "\n",
    "#############################################################################################\n",
    "#\n",
    "def load_datasets_qcd(lumi=300., nevents=None, skip=0, verbosity=0):\n",
    "\n",
    "    # Open ROOT file with uproot\n",
    "    samples = [\n",
    "        \"QCD_Pt-20To30\",\n",
    "        \"QCD_Pt-30To50\",\n",
    "        \"QCD_Pt-50To80\",\n",
    "        \"QCD_Pt-80To120\",\n",
    "        \"QCD_Pt-120To170\",\n",
    "        \"QCD_Pt-170To300\",\n",
    "        \"QCD_Pt-300To470\",\n",
    "        \"QCD_Pt-470To600\",\n",
    "        \"QCD_Pt-600ToInf\",\n",
    "    ][::-1] # reversed !!!\n",
    "\n",
    "    cross_sections_pb = [\n",
    "        432900000., # == ~0.4 mb\n",
    "        117200000.,\n",
    "        17490000.,\n",
    "        2657000.,\n",
    "        467800.,\n",
    "        120300.,\n",
    "        8157.,\n",
    "        683.1,\n",
    "        241.6,\n",
    "    ][::-1] # reversed !!!\n",
    "    cross_sections_fb = [ xs * 1.e3 for xs in cross_sections_pb]\n",
    "    \n",
    "    labels = [\n",
    "        \"QCD (20-30)\",\n",
    "        \"QCD (30-50)\",\n",
    "        \"QCD (50-80)\",\n",
    "        \"QCD (80-120)\",\n",
    "        \"QCD (120-170)\",\n",
    "        \"QCD (170-300)\",\n",
    "        \"QCD (300-470)\",\n",
    "        \"QCD (470-600)\",\n",
    "        \"QCD (600-Inf)\",\n",
    "    ][::-1] # reversed !!!\n",
    "    labels = dict(zip(samples,labels))\n",
    "\n",
    "    return load_datasets(\n",
    "        samples,\n",
    "        labels=labels,\n",
    "        path=\"../data/Phase2/QCD/\",\n",
    "        cross_sections=cross_sections_fb,\n",
    "        lumi=lumi,\n",
    "        nevents=nevents, skip=skip, verbosity=verbosity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful documentation\n",
    "# https://plothist.readthedocs.io/en/latest/index.html (super useful)\n",
    "# https://hist.readthedocs.io/en/latest/ (hmmm...)\n",
    "# https://boost-histogram.readthedocs.io/en/latest/index.html (backend for histograms)\n",
    "# https://mplhep.readthedocs.io/en/latest/ (matplotlib styles for CMS)\n",
    "\n",
    "#############################################################################################\n",
    "#\n",
    "def histos_1d(\n",
    "    datasets,\n",
    "    xvar,\n",
    "    **kwargs): \n",
    "\n",
    "    nbins = 50 if \"nbins\" not in kwargs else kwargs[\"nbins\"]\n",
    "    start = 0. if \"start\" not in kwargs else kwargs[\"start\"]\n",
    "    stop = 100. if \"stop\" not in kwargs else kwargs[\"stop\"]\n",
    "    \n",
    "    histos = {}\n",
    "    for dataset,dict in datasets.items():\n",
    "        events = dict[\"events\"]\n",
    "        label = dict[\"label\"]\n",
    "        var = events[xvar]\n",
    "        mask = ~ak.is_none(var)\n",
    "        var = ak.drop_none(var[mask])\n",
    "        wei = ak.drop_none(events[\"weight\"][mask])\n",
    "        histo = make_hist(var, bins=nbins, range=[start,stop], weights=wei)\n",
    "        histos[dataset] = {\"label\":label, \"histo\":histo}\n",
    "    return histos\n",
    "\n",
    "#############################################################################################\n",
    "#\n",
    "def plot_1d(\n",
    "        background_histos,\n",
    "        signal_histos=None,\n",
    "        lumi=300.,\n",
    "        **kwargs):\n",
    "\n",
    "    nbins = 50 if \"nbins\" not in kwargs else kwargs[\"nbins\"]\n",
    "    start = 0. if \"start\" not in kwargs else kwargs[\"start\"]\n",
    "    stop = 100. if \"stop\" not in kwargs else kwargs[\"stop\"]\n",
    "    xlabel = \"Unknown\" if \"xlabel\" not in kwargs else kwargs[\"xlabel\"]\n",
    "    ylabel = \"Arbitrary\" if \"ylabel\" not in kwargs else kwargs[\"ylabel\"] \n",
    "    bins = np.linspace(start, stop, nbins+1)\n",
    "    centers = (bins[:-1] + bins[1:]) / 2\n",
    "    year = 2023 if \"year\" not in kwargs else kwargs[\"year\"]\n",
    "    com = 13.6 if \"com\" not in kwargs else kwargs[\"com\"]\n",
    "    lumi = lumi if \"lumi\" not in kwargs else kwargs[\"lumi\"]\n",
    "    ymin = 0.1 if \"ymin\" not in kwargs else kwargs[\"ymin\"]\n",
    "    ymax = 1.e3 if \"ymax\" not in kwargs else kwargs[\"ymax\"]\n",
    "\n",
    "    bkg_histos = [background_histos[dataset][\"histo\"] for dataset in background_histos.keys() if \"QCD\" in dataset]\n",
    "    bkg_labels = [background_histos[dataset][\"label\"] for dataset in background_histos.keys() if \"QCD\" in dataset]\n",
    "    bkg_colors = [\"red\",\"blue\",\"green\",\"orange\",\"purple\",\"brown\",\"pink\",\"cyan\",\"magenta\"][:len(bkg_labels)]\n",
    "\n",
    "    sig_histos = [signal_histos[dataset][\"histo\"] for dataset in signal_histos.keys() if \"HHTo4B\" in dataset] if signal_histos is not None else []\n",
    "    sig_labels = [signal_histos[dataset][\"label\"] for dataset in signal_histos.keys() if \"HHTo4B\" in dataset] if signal_histos is not None else None\n",
    "    sig_colors = [\"black\",\"gray\"][:len(sig_labels)] if signal_histos is not None else None\n",
    "    sig_kwargs = [{\"linestyle\": \"dotted\", \"linewidth\":2},{\"linestyle\": \"dashed\"},][:len(sig_labels)] if signal_histos is not None else []\n",
    "\n",
    "    plt.style.use([hep.style.CMS, hep.style.firamath])\n",
    "    fig, ax = plot_model(\n",
    "        stacked_components=bkg_histos,\n",
    "        stacked_labels=bkg_labels,\n",
    "        stacked_colors=bkg_colors,\n",
    "        unstacked_components=sig_histos,\n",
    "        unstacked_labels=sig_labels,\n",
    "        unstacked_colors=sig_colors,\n",
    "        unstacked_kwargs_list=sig_kwargs,\n",
    "        xlabel=xlabel,\n",
    "        ylabel=ylabel,\n",
    "        model_sum_kwargs={\"show\": True, \"label\": \"Total\", \"color\": \"black\"},\n",
    "        model_uncertainty_label=\"Stat. unc.\",\n",
    "    )\n",
    "    plt.legend(fontsize=15)\n",
    "\n",
    "    bkg_total = make_hist(bins=nbins, range=[start,stop])\n",
    "    for h in bkg_histos: bkg_total.view().value += h.view().value\n",
    "    print(f\"Total expected number of events in {lumi}/fb for the bkgd process:  \",bkg_total.view().sum())\n",
    "\n",
    "    if signal_histos is not None:\n",
    "        sig_total = make_hist(bins=nbins, range=[start,stop])\n",
    "        for h in sig_histos: sig_total.view().value += h.view().value\n",
    "        print(f\"Total expected number of events in {lumi}/fb for the signal process:\",sig_total.view().sum())\n",
    "\n",
    "    # y axis range\n",
    "    ymax = 2. * max(bkg_total.view().value)\n",
    "    ax.set_ylim(bottom=0.1,top=ymax)\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    hep.cms.label(\"Preliminary\",data=False, year=year, com=com, lumi=lumi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################\n",
    "#\n",
    "def plot_1d_gen_pt_hat(bkg_datasets, sig_datasets=None, lumi=300., nevents=None, skip=0, verbosity=0):\n",
    "    nbins, start, stop = 100, 0., 1000.; width = (stop - start) / nbins\n",
    "    kwargs = {\n",
    "        \"nbins\":nbins, \"start\":start, \"stop\":stop,\n",
    "        \"xlabel\":\"GEN $\\hat{p_{T}}$ [GeV]\", \n",
    "        \"ylabel\":f\"Entries / {width:.0f} GeV\",\n",
    "        \"year\":None, \"com\":14, \"lumi\":lumi}\n",
    "    sig_histos = histos_1d(sig_datasets,\"gen_pt_hat\",**kwargs)\n",
    "    qcd_histos = histos_1d(bkg_datasets,\"gen_pt_hat\",**kwargs)\n",
    "    plot_1d(qcd_histos,sig_histos,**kwargs)\n",
    "\n",
    "#############################################################################################\n",
    "#\n",
    "def plot_1d_reco_ht_lead4jets(bkg_datasets, sig_datasets=None, lumi=300., nevents=None, skip=0, verbosity=0):\n",
    "\n",
    "    # Calculate HT from the leading 4 jets\n",
    "    for _,dataset in bkg_datasets.items():\n",
    "        events = dataset[\"events\"]\n",
    "        mask = (events.Jet_pt > 10.) & (abs(events.Jet_eta) < 2.5)\n",
    "        events[\"HT\"] = ak.sum(events[\"Jet_pt\"][mask][:,:4],axis=-1)\n",
    "\n",
    "    for _,dataset in sig_datasets.items():\n",
    "        events = dataset[\"events\"]\n",
    "        mask = (events.Jet_pt > 10.) & (abs(events.Jet_eta) < 2.5)\n",
    "        events[\"HT\"] = ak.sum(events[\"Jet_pt\"][mask][:,:4],axis=-1)\n",
    "\n",
    "    nbins, start, stop = 100, 0., 2000.; width = (stop - start) / nbins\n",
    "    kwargs = {\n",
    "        \"nbins\":nbins, \"start\":start, \"stop\":stop,\n",
    "        \"xlabel\":\"$H_{T}$ [GeV] (leading 4 jets)\", \n",
    "        \"ylabel\":f\"Entries / {width:.0f} GeV\",\n",
    "        \"year\":None, \"com\":14, \"lumi\":lumi}\n",
    "    sig_histos = histos_1d(sig_datasets,\"HT\",**kwargs)\n",
    "    qcd_histos = histos_1d(bkg_datasets,\"HT\",**kwargs)\n",
    "    plot_1d(qcd_histos,sig_histos,**kwargs)\n",
    "\n",
    "#############################################################################################\n",
    "#\n",
    "def plot_1d_reco_ht_alljets(bkg_datasets, sig_datasets=None, lumi=300., nevents=None, skip=0, verbosity=0):\n",
    "\n",
    "    # Calculate HT from the leading 4 jets\n",
    "    for _,dataset in bkg_datasets.items():\n",
    "        dataset[\"events\"][\"HT\"] = ak.sum(dataset[\"events\"][\"Jet_pt\"][:,:4],axis=-1)\n",
    "    for _,dataset in sig_datasets.items():\n",
    "        dataset[\"events\"][\"HT\"] = ak.sum(dataset[\"events\"][\"Jet_pt\"][:,:4],axis=-1)\n",
    "\n",
    "    nbins, start, stop = 100, 0., 2000.; width = (stop - start) / nbins\n",
    "    kwargs = {\n",
    "        \"nbins\":nbins, \"start\":start, \"stop\":stop,\n",
    "        \"xlabel\":\"$H_{T}$ [GeV] (leading 4 jets)\", \n",
    "        \"ylabel\":f\"Entries / {width:.0f} GeV\",\n",
    "        \"year\":None, \"com\":14, \"lumi\":lumi}\n",
    "    sig_histos = histos_1d(sig_datasets,\"HT\",**kwargs)\n",
    "    qcd_histos = histos_1d(bkg_datasets,\"HT\",**kwargs)\n",
    "    plot_1d(qcd_histos,sig_histos,**kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXECUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selections_bbbb(**kwargs):\n",
    "    \n",
    "    # Default settings\n",
    "    nevents = kwargs[\"nevents\"] if \"nevents\" in kwargs.keys() else 10000\n",
    "    skip = kwargs[\"skip\"] if \"skip\" in kwargs.keys() else 0\n",
    "    verbosity = kwargs[\"verbosity\"] if \"verbosity\" in kwargs.keys() else 0\n",
    "    gen_pt_min = kwargs[\"gen_pt_min\"] if \"gen_pt_min\" in kwargs.keys() else 10.\n",
    "    gen_eta_max = kwargs[\"gen_eta_max\"] if \"gen_eta_max\" in kwargs.keys() else 2.5\n",
    "    off_pt_min = kwargs[\"off_pt_min\"] if \"off_pt_min\" in kwargs.keys() else 35.\n",
    "    off_eta_max = kwargs[\"off_eta_max\"] if \"off_eta_max\" in kwargs.keys() else 2.5\n",
    "    off_btag_min = kwargs[\"off_btag_min\"] if \"off_btag_min\" in kwargs.keys() else 0. #@@ DEFAULT IS ZERO ???\n",
    "    sct_pt_min = kwargs[\"sct_pt_min\"] if \"sct_pt_min\" in kwargs.keys() else 20.\n",
    "    sct_eta_max = kwargs[\"sct_eta_max\"] if \"sct_eta_max\" in kwargs.keys() else 2.5\n",
    "    use_matched = kwargs[\"use_matched\"] if \"use_matched\" in kwargs.keys() else False\n",
    "    lumi = kwargs[\"lumi\"] if \"lumi\" in kwargs.keys() else 300.\n",
    "    \n",
    "    _, sig_datasets = load_datasets_signal(nevents=nevents, lumi=lumi, skip=skip, verbosity=verbosity)\n",
    "    bkg_events, bkg_datasets = load_datasets_qcd(nevents=nevents, lumi=lumi, skip=skip, verbosity=verbosity)\n",
    "    \n",
    "    if verbosity>=2:\n",
    "        print()\n",
    "        print(\"FULL DEBUG MODE!!!\")\n",
    "        print(\" Verbosity: \", verbosity)\n",
    "        print(\" Num evts:  \", len(bkg_events[\"nGenPart\"]))\n",
    "\n",
    "    plot_1d_gen_pt_hat(bkg_datasets, sig_datasets=sig_datasets, lumi=lumi, nevents=nevents, skip=skip, verbosity=verbosity)\n",
    "    plot_1d_reco_ht_lead4jets(bkg_datasets, sig_datasets=sig_datasets, lumi=lumi, nevents=nevents, skip=skip, verbosity=verbosity)\n",
    "\n",
    "settings = settings_.copy()\n",
    "settings.update({\"off_btag_min\":0.})\n",
    "print(settings)\n",
    "selections_bbbb(**settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "root6-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
